{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Small Tour Into Imaging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Among other, we will learn:\n",
    "\n",
    " - **Linear algebra** is ubiquitous in imaging (and signal processing in general)\n",
    " - **convolution**/**filter**, **Toeplitz** matrix, **Kronecker** product, **flattening**, **padding**/boundary conditions\n",
    " - We need **sparse formats** to deal with high-dimensional image data\n",
    " - **Iterative methods** to approximate solutions\n",
    " - Application: **Image inpainting**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Motivation**\n",
    "\n",
    "Suppose you find yourself in the following situation: \n",
    "\n",
    "Some bytes and bits of your favourite photo have been corrupted (set to zero) and the image now looks like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"media/kalle_firstapproach.png\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let the resolution be $H \\times W$ (= shape of the image) and assume you can measure, which pixels are precisely lost in the image. \n",
    "\n",
    "What could you do to reconstruct your original image?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's apply our toolbox:\n",
    "\n",
    " - We are given some noisy image $b\\in\\mathbb{R}^n$ (flattened, $n=HW$)\n",
    " - We are looking for the original, high-resolution image $x \\in \\mathbb{R}^n$\n",
    " - We know the linear distortion operator $A \\in \\mathbb{R}^{n \\times n}$, which has set some pixels to zero and produced $$b = Ax.$$ This $A$ is obtained from the identity matrix by setting the diagonal entries to zero where the pixels are lost.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We could try to recover the original image from solving this equation. Would this be a good idea?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "No! Because taking $b$ and setting the lost pixels to any color value would be a solution here. \n",
    "\n",
    "In fact, the problem is ill-posed (existence, but not uniqueness)!\n",
    "\n",
    "One solution would be $Ab =b.$ (Observe that $A$ is an orthogonal projector, therefore $A^2 = A$)\n",
    "\n",
    "<img src=\"media/kalle_firstapproach.png\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Well, we could formulate a least squares problem:\n",
    "\n",
    "$$\\min_x \\|Ax-b\\|_2^2$$\n",
    "\n",
    "Is this better now?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "No, because we have just found an $x$ which solves the equation exactly. \n",
    "\n",
    "And this solution $x=b$ is precisely the minimum-norm least squares solution, i.e., we just get back our noisy image $b$.\n",
    "\n",
    "\n",
    "Any other ideas?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "What about Tikhonov regularization?\n",
    "\n",
    "$$\\min_x \\|Ax-b\\|_2^2 + \\frac{\\delta}{2}\\|x\\|^2_2.$$\n",
    "\n",
    "Better?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "With the $A$ from above ($A^\\top = A, Ab=b$) the system\n",
    "\n",
    "$$(A^\\top A + \\delta I)x = A^\\top b $$\n",
    "\n",
    "is equivalent to this diagonal system\n",
    "\n",
    "$$(A + \\delta I)x = b .$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The solution $x=x_\\delta$ is thus given by\n",
    "\n",
    "$$x_i = \n",
    "\\begin{cases}\n",
    "\\frac{b_i}{1+\\delta}&: \\text{known pixel}\\\\\n",
    "\\frac{b_i}{\\delta}&: \\text{lost pixel}\n",
    "\\end{cases}\n",
    "= \n",
    "\\begin{cases}\n",
    "\\frac{b_i}{1+\\delta}&: \\text{known pixel}\\\\\n",
    "0&: \\text{lost pixel}\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This is also not going to bring us any further. \n",
    "\n",
    "However a regularized least squares problem is the right direction:\n",
    "\n",
    "$$\\min_x \\|Ax-b\\|_2^2 + \\frac{\\delta}{2}\\|Dx\\|_2^2.$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The problem with Tikohonov regularization ($D=I$) is that it only considers local information.\n",
    "\n",
    "\n",
    "Improvement in the example later on:\n",
    "- We will define $D$ in such a way that it penalizes huge differences between neighboring pixels.\n",
    "- Thereby information from the direct neighbors will we be considered in the optimization problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This is referred to Sobolev regularization and the result may look like this\n",
    "\n",
    "![intro](./media/intro_kalle_solved.png)\n",
    "\n",
    "\n",
    "... not too bad!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The outline:\n",
    "\n",
    " - Generalizing Tikhonov Regularization\n",
    " - Working with images: Flattening, filters (1d, 2d),...\n",
    " - Worked Example: Inpainting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Generalizing Tikhonov Regularization\n",
    "\n",
    "We have slightly modified the Tikhonov regularization term by allowing linear transformations before the norm is evaluated. For some matrix $D \\in \\mathbb{R}^{p \\times n}$, consider\n",
    "\n",
    "$$\\min_x \\|Ax-b\\|_2^2 + \\frac{\\delta}{2}\\|Dx\\|_2^2.$$\n",
    "\n",
    "\n",
    "The necessary first--order optimality conditions then read as\n",
    "\n",
    "\\begin{equation}\\label{eq:regularized_normaleq}\n",
    "(A^\\top A + \\delta D^\\top D) x = A^\\top b. \n",
    "\\end{equation}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    " - Problems of this nature are also called *inverse problems*, as we go inverse from the measured data (here $b$) to the original parameters, which have produced these measurements but are not directly observable.\n",
    " - Different choices of distortion operators $A$ lead to different applications: Inpainting (here), super-resolution, sub-sampling, ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " More remarks:\n",
    " \n",
    " $$\\min_x \\|Ax-b\\|_2^2 + \\tfrac{\\delta}{2}\\|Dx\\|_2^2$$\n",
    " \n",
    " - The first term in the objective is of matching-type and makes sure that the recovered data has something to do with the measurements.\n",
    " - The regularization term, here $\\frac{\\delta}{2}\\|Dx\\|_2^2$, is sometimes referred to as *prior* and is used to prescribe desired (smoothness) properties for the solution and thus assumes *prior* knowledge on the kind of data one expects to restore.\n",
    "   - For example: If $D$ evaluates the differences between neighboring pixels, then by increasing $\\delta$, these have to become small in order to minimize this part of the objective function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    " - For appropriate choices of $D$ (examples below), we obtain a well-posed problem.\n",
    " - Observe that for $D = I$ we obtain the standard Tikhonov (or $L^2$-) regularization. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Working with Images\n",
    "\n",
    "- We look at some basics and avoid the usage of preimplemented libraries to understand the underlying concepts.\n",
    "\n",
    "- How are images stored in a computer? <img src=\"media/image.png\" width=\"1200\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "   - take a regular squared grid\n",
    "   - for each square in the grid we store a number (or triple of numbers) which represents a color\n",
    "   - the more squares (picture elements) the higher the resolution and storage demand\n",
    "   - all in all, this results in a table of numbers (or more tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import ipywidgets as widgets\n",
    "import matplotlib_inline.backend_inline\n",
    "matplotlib_inline.backend_inline.set_matplotlib_formats('svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'kalle.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-cfc4a6d2c6b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpath_to_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"kalle.jpg\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"L\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"---\\nType: {typ}\\nDimension/Resolution: {dim}\\n---\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtyp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gray\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2807\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2808\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2809\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2810\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'kalle.jpg'"
     ]
    }
   ],
   "source": [
    "path_to_img = \"kalle.jpg\"\n",
    "img = np.array(Image.open(path_to_img).convert(\"L\"))\n",
    "print(\"---\\nType: {typ}\\nDimension/Resolution: {dim}\\n---\".format(typ=type(img), dim=img.shape))\n",
    "plt.imshow(img, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Having the image loaded as a numpy array is very powerful and allows any sort of array manipulation!\n",
    "\n",
    "*(Pointwise functions explained on the blackboard)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def lighten(img, percent):\n",
    "    # convex combination with 1's\n",
    "    return (1 - percent) * img +  percent * (255 * np.ones(img.shape))\n",
    "\n",
    "@widgets.interact_manual(percent=(0.0, 1.0))\n",
    "def plot(percent=0):\n",
    "    plt.imshow(lighten(img.copy(), percent), cmap=\"gray\", vmin=0, vmax=255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def darken(img, percent):\n",
    "    # convex combination with 0's\n",
    "    return (1-percent)*img\n",
    "\n",
    "@widgets.interact_manual(percent=(0.1, 1.0))\n",
    "def plot(percent=0):\n",
    "    plt.imshow(darken(img.copy(),percent), cmap=\"gray\", vmin=0, vmax=255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def brightness(img, brightness_factor):\n",
    "    # shift by a constant and project on (0,255)\n",
    "    img = img + brightness_factor * 255. * np.ones(img.shape)\n",
    "    img[img > 255] = 255\n",
    "    img[img < 0] = 0\n",
    "    return img.astype(\"int\")\n",
    "\n",
    "@widgets.interact_manual(brightness_factor=(-1.0, 1.0))\n",
    "def plot(brightness_factor=0):\n",
    "    plt.imshow(brightness(img.copy(),brightness_factor), cmap=\"gray\", vmin=0, vmax=255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def flip(img, direction= \"lr\"):\n",
    "    if direction == \"lr\":\n",
    "        return np.fliplr(img)\n",
    "    else:\n",
    "        return np.flipud(img)\n",
    "\n",
    "@widgets.interact_manual(direction=[\"lr\", \"ud\"])\n",
    "def plot(direction=0):\n",
    "    plt.imshow(flip(img.copy(), direction), cmap=\"gray\", vmin=0, vmax=255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def contrast(img, lower_threshold=\"122\", upper_threshold=\"122\"):\n",
    "    img[img < lower_threshold] = 0  # black\n",
    "    img[img >= upper_threshold] = 255  # white\n",
    "    return img\n",
    "\n",
    "@widgets.interact_manual(lower_threshold=(0, 255), upper_threshold=(0, 255))\n",
    "def plot(lower_threshold=0, upper_threshold=0):\n",
    "    plt.imshow(contrast(img.copy(), lower_threshold, upper_threshold), cmap=\"gray\", vmin=0, vmax=255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Flattening\n",
    "- For applying linear transformations to the image, like computing local averages, it is convenient to flatten the image (2d data) into a vector (1d data). \n",
    "- Linear transformations of the image then become matrix-vector products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "n = 5\n",
    "b = np.arange(0, n**2, 1, dtype=\"int\").reshape(n,n)\n",
    "\n",
    "plt.imshow(b)\n",
    "for (j,i),label in np.ndenumerate(b):\n",
    "    plt.text(i, j, label, ha='center', va='center', fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "for order, title in zip(['C', 'F'], [\"C: default flatten in row-major\", \"F: flatten in column-major\"]):\n",
    "    b_flat = b.reshape(1,n**2,order=order)\n",
    "    plt.figure(), plt.imshow(b_flat, interpolation=\"nearest\"), plt.title(title), plt.axis(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "*Blackboard:*\n",
    "\n",
    "**Mathematically**: Let $m$ and $n$ be height and width, respectively.\n",
    "\n",
    "Let $b \\in \\mathbb{R}^{m \\times n}$ and $\\text{vec}(b) \\in\\mathbb{R}^{mn}$ be the flattened version of $b$. \n",
    "\n",
    "If row-major order is applied, then the index map from matrix to vector is given by\n",
    "$$b(i,j) =  \\text{vec}(b)(i\\cdot n + j),~~0\\leq i \\leq m-1,~ 0\\leq j \\leq n-1, $$\n",
    "and from vector to matrix by\n",
    "$$\\text{vec}(b)(k) =  b(k // n, k \\%n),~~0\\leq k \\leq mn-1.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Translationally Invariant Filters \n",
    "\n",
    "The important keywords:\n",
    "\n",
    " - **convolution**/**filter** \n",
    " - (two-level) **Toeplitz** matrix\n",
    " - separable 2d filter = **Kronecker** product of 1d filter (=one-level Toeplitz)\n",
    " - **padding**/boundary conditions (particularly for more nonlocal filters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 1d Introductory Example \n",
    "\n",
    "Assume we have a discrete 1d signal, i.e., a vector `signal` $\\in \\mathbb{R}^n$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "n = 150\n",
    "noise = 0.1\n",
    "x = np.linspace(-6,6,n) \n",
    "signal = np.sin(x) + np.random.normal(0, noise, n)\n",
    "plt.plot(x, signal)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now we would like to transform this 1d signal into a new vector, say `signal_filtered` $\\in \\mathbb{R}^n$, by applying a *moving* average of size $k$, so that formally for the interior points\n",
    "\n",
    "$$\\text{signal_filtered}(i) := \\frac{1}{n}\\sum_{j=i-k//2}^{i+k//2} \\texttt{signal}(j)$$\n",
    "\n",
    "This corresponds to the 1d average filter\n",
    "\n",
    "$$\\frac{1}{n} [1,1,\\cdots,1].$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "*Blackboard:*\n",
    "\n",
    "Let us translate this operation into a matrix-vector product\n",
    "\n",
    " - Padding to deal with boundary points.\n",
    " - Derive Toeplitz matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def average_1d(horizon):\n",
    "    return [1./horizon] * horizon\n",
    "\n",
    "def filter_matrix_1d(weights, dim, normalize=1):\n",
    "    import numpy as np\n",
    "    import scipy.linalg as linalg\n",
    "    import scipy.sparse as sparse\n",
    "    kernel_horizon = len(weights)\n",
    "    row = np.append(weights, np.zeros(dim - kernel_horizon))\n",
    "    if normalize:\n",
    "        row *= 1./ np.sum(row)\n",
    "    col = np.zeros(dim)\n",
    "    col[0] = row[0]\n",
    "    A = linalg.toeplitz(col, row) \n",
    "    A = sparse.csr_matrix(A)\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "signal_padded = np.pad(signal, 1, mode=\"reflect\")  #  constant\n",
    "print(\"signal_padded[0:3] =\", signal_padded[0:3])\n",
    "horizon = 10\n",
    "weights = average_1d(horizon)\n",
    "A = filter_matrix_1d(weights, len(signal_padded), normalize=0)\n",
    "signal_filtered = A.dot(signal_padded)\n",
    "plt.plot(x, signal_filtered[0:-2]) # cropped due to padding\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Observation: The moving average is very good in reducing random noise while retaining the shape of the signal\n",
    "\n",
    "We say: \"convolution smoothens\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 2d case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Now we want to proceeed in the same fashion and apply a weighted averaging on each pixel:\n",
    "\n",
    "Average filter:\n",
    "$$\\frac{1}{9}\\begin{pmatrix}1&1&1\\\\1&1&1\\\\1&1&1\\end{pmatrix}= xx^\\top ,~~~x = \\frac{1}{3}\\begin{pmatrix}1\\\\1\\\\1\\end{pmatrix} $$\n",
    "\n",
    "Gaussian filter:\n",
    "$$\\frac{1}{16}\\begin{pmatrix}1&2&1\\\\2&4&2\\\\1&2&1\\end{pmatrix} = xx^\\top ,~~~x = \\frac{1}{4}\\begin{pmatrix}1\\\\2\\\\1\\end{pmatrix}$$\n",
    "\n",
    "-> translationally invariant (same for each pixel) and separable (rank 1) filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib_inline.backend_inline\n",
    "matplotlib_inline.backend_inline.set_matplotlib_formats('svg')\n",
    "%matplotlib inline\n",
    "\n",
    "def show_image(matrix, title=\"\", cmap=\"gray\", vmin=0, vmax=1, plot_numbers=False):\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    plt.imshow(matrix, cmap, vmin=vmin, vmax=vmax)\n",
    "    if plot_numbers:\n",
    "        for (j, i), label in np.ndenumerate(matrix):\n",
    "            plt.text(i, j, np.round(matrix[i, j], 1), ha='center', va='center', fontsize=7)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**2d filter from 1d filter**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def plot_filter(weights):\n",
    "    plt.figure()\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(weights, '-')\n",
    "    plt.axis(False)\n",
    "    plt.title(\"1d: x\")\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(np.outer(weights, weights))\n",
    "    plt.axis(False)\n",
    "    plt.title(\"2d: xx.T\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def gaussian_1d(sigma, horizon):\n",
    "    # mu = 0\n",
    "    g = lambda x: np.exp(- 0.5 * (x / sigma) ** 2) * 1 / (np.sqrt(2 * np.pi) * sigma)\n",
    "    X = np.linspace(- (horizon // 2), horizon // 2, horizon, endpoint=True)\n",
    "    return g(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "horizon = 40\n",
    "sigma = 0.2*horizon\n",
    "plot_filter(gaussian_1d(sigma, horizon))\n",
    "plot_filter(average_1d(horizon))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Example Image**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def example_image(n):\n",
    "    import numpy as np\n",
    "    img = np.zeros((n,n))\n",
    "    img[int(0.35*n):int(0.65*n), int(0.35*n):int(0.65*n)] = 1\n",
    "    return img\n",
    "\n",
    "n = 10\n",
    "b = example_image(n)\n",
    "show_image(b, \"original image\", plot_numbers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Padding with `numpy.pad`**\n",
    "\n",
    "How to compute the average for the boundary pixels?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "One common approach is to extend the image with an artificial \"nonlocal boundary\". \n",
    "\n",
    "Again, we use `numpy.pad`: https://numpy.org/doc/stable/reference/generated/numpy.pad.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "horizon = 4\n",
    "pad_width = horizon // 2\n",
    "b = np.random.rand(n,n)\n",
    "b_padded = np.pad(b, pad_width=horizon//2, mode=\"reflect\") # mode = constant, minimum, symmetric, reflect,...\n",
    "n_padded = n + 2 * pad_width\n",
    "show_image(b, \"original\", plot_numbers=1)\n",
    "show_image(b_padded, \"padded\", plot_numbers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Filter Matrix Construction**\n",
    "\n",
    "For constructing the application of the filter as a matrix-vector product we expect the image to be already padded.\n",
    "\n",
    "We will not go into detail here and instead recommend Sections IV.3-5 in Strang's book *Linear Algebra and Learning from Data*.\n",
    "\n",
    "The ideas come from the 1d case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def filter_matrix_2d(weights, width, normalize=1):\n",
    "    import scipy.sparse\n",
    "    A = filter_matrix_1d(weights, width, normalize=1)\n",
    "    A = scipy.sparse.kron(A, A)\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def apply_filter(b, A, horizon, pad_mode=\"symmetric\"):\n",
    "    \"\"\"padding and matrix-vector product\"\"\"\n",
    "    m, n = np.shape(b)\n",
    "    # pad the original image\n",
    "    pad_width = horizon // 2\n",
    "    b_padded = np.pad(b, pad_width=horizon//2, mode=pad_mode)\n",
    "    n_padded = n + 2 * pad_width\n",
    "    b_padded_flat = b_padded.reshape(n_padded ** 2,1)\n",
    "    # apply filter and de-pad\n",
    "    b_padded_flat_filtered = A.dot(b_padded_flat)\n",
    "    b_padded_filtered = b_padded_flat_filtered.reshape(n_padded, n_padded, order=\"C\")\n",
    "    b_filtered = b_padded_filtered[0:n, 0:n]  # explain\n",
    "    b_filtered_flat = b_filtered.reshape(n**2, 1)\n",
    "    return b_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "n = 50  # 50\n",
    "horizon = 20  # 10\n",
    "plot_numbers = True \n",
    "b = example_image(n)   # np.random.rand(n,n)  #  \n",
    "weights = gaussian_1d(10, horizon)  # average_1d(horizon)  # \n",
    "A = filter_matrix_2d(weights, n + 2 * (horizon // 2) , normalize=1)\n",
    "b_filtered = apply_filter(b, A, horizon, pad_mode=\"symmetric\")\n",
    "show_image(b, \"original image\", plot_numbers=0)\n",
    "show_image(b_filtered, \"filtered image\",plot_numbers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Worked Example: [Image Inpainting](https://en.wikipedia.org/wiki/Inpainting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We are given the flattened noisy image $b$, which results from the unknown flattened original image $x$ through the following masking operation\n",
    "\\begin{equation} \\label{eq:masking_operation}\n",
    " b_i =(Ax)_i = \\begin{cases}\n",
    "x_i & i \\in \\texttt{indices},\\\\\n",
    "0 & \\text{else},\n",
    "\\end{cases}\n",
    "\\end{equation}\n",
    "where $\\texttt{indices}$ is a list of random pixels. \n",
    "\n",
    "In words, the pixels in $\\texttt{indices}$ survived, the rest is lost (set to zero). We want to recover those lost pixels. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "As discussed above, the masking operation can be written as a matrix-vector product\n",
    "$$b = Ax $$\n",
    "for some quadratic matrix $A$. \n",
    "\n",
    "We will seek for solutions of the regularized least squares problem\n",
    "\n",
    "$$\\min_x \\|Ax-b\\|_2^2 + \\frac{\\delta}{2}\\|Dx\\|_2^2.$$\n",
    "\n",
    "by solving\n",
    "\n",
    "$$\n",
    "(A^\\top A + \\delta D^\\top D) x = A^\\top b. \n",
    "$$\n",
    "\n",
    "For this purpose will choose a particular $D$ which is related to Sobolev (or $H^1$-) regularization (details below). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Outline**\n",
    "\n",
    " - implement function `A = masking_matrix(image_shape, percentage)`\n",
    " - implement function `D = difference_matrix(image_shape)`\n",
    " - implement function `b = distortion(A, img)` (to obtain test data $b$)\n",
    " - implement function `x = reg_lstsq(A, b, D, reg_param=0.1)` to solve the regularized normal equation\n",
    " - plot the results and play around with the parameters\n",
    " \n",
    " \n",
    " - Due to the high dimensional image data ($n = HW$!) we need to work with *sparse* matrices. Also, we will apply iterative methods which only require matrix-vector products and potentially few iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Masking: `A = masking_matrix(image_shape, percentage)`** \n",
    "\n",
    "`percentage` in (0,1) indicates the percentage of pixels that are randomly kept. \n",
    "\n",
    "The sparse  $(n \\times n)$ masking matrix $A$ is zero everywhere except for $a_{ii} = 1$ for $i \\in$`indices`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def masking_matrix(image_shape, percentage):\n",
    "    \"\"\"Randomly sets (1-percentage)*100 % of the pixels to zero, i.e.\n",
    "    percentage*100% of the pixels are kept\"\"\"\n",
    "    import numpy as np\n",
    "    import scipy.sparse as sparse\n",
    "    dim = np.prod(image_shape)    \n",
    "    if percentage == \"patch\":\n",
    "        #patch_size = int(0.1 * dim)\n",
    "        #H, W = image_shape\n",
    "        #indices = [i * W + j for i in range(patch_size, 2*patch_size) for j in range(patch_size,2*patch_size)]\n",
    "        pass\n",
    "    else:\n",
    "        indices = np.random.choice(np.arange(dim), replace=False, size=int(dim * percentage))\n",
    "    A = sparse.coo_matrix((np.ones(len(indices)),\n",
    "                           (indices, indices)), shape=(dim, dim)).tocsr()\n",
    "    A = A.tocsr()\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def test_masking_matrix(image_shape, percentage):\n",
    "    import numpy as np\n",
    "    A = masking_matrix(image_shape, percentage)\n",
    "    dim = np.prod(image_shape) \n",
    "    assert A.shape == (dim, dim), \"masking matrix has wrong dimension\"\n",
    "    assert A.data.size == int(dim * percentage), \"masking matrix has more nonzeroes than expected\"\n",
    "    assert A.data == [1] * int(dim * percentage), \"masking matrix has other nonzeroes than 1's\"\n",
    "    assert (A.T - A).data.size == 0, \"masking matrix not symmetric\"\n",
    "    assert (A @ A - A).data.size == 0, \"masking matrix not idempotent\"\n",
    "test_masking_matrix((3,4), 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Regularization: `D = difference_matrix(image_shape)`**\n",
    "\n",
    " - Develop on blackboard for simple 2x3 example.\n",
    " - Idea\n",
    "   - We want to use \"nonlocal\" information from direct neighbors.\n",
    "   - More precisely, we will penalize differences between horizontal and vertical neighbors (five-point stencil)\n",
    "   - We can think of it as incidence matrix of a graph: Let image be of size $H \\times W$\n",
    "     - horizontal differences/edges = $H(W-1)$\n",
    "     - vertical differences/edges = $(H-1)W$\n",
    "     - total number of edges $p = 2HW - H - W$\n",
    "     - we encode the nodes belonging to an edges with 1 and -1 \n",
    "     - all in all the difference matrix is of size $p\\times HW$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "H, W = 2, 3\n",
    "n = H * W\n",
    "G_horizontal = np.kron(np.eye(H), np.eye(W-1, W, k=0) - np.eye(W-1, W, k=1))\n",
    "G_vertical = np.kron(np.eye(H-1, H, k=0) - np.eye(H-1, H, k=1), np.eye(W))\n",
    "G = np.vstack((G_horizontal, G_vertical))\n",
    "print(G.astype(\"int\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def difference_matrix(image_shape):\n",
    "    \"\"\"returns difference matrix D; shape = edges x nodes (graph=squared grid)\"\"\"\n",
    "    import scipy.sparse as sparse\n",
    "    H, W = image_shape\n",
    "    n = H * W\n",
    "    D = sparse.eye(n+1, n, k=0) - sparse.eye(n+1, n, k=-1)\n",
    "    D_horizontal = sparse.kron(sparse.eye(H), sparse.eye(W-1, W, k=0) - sparse.eye(W-1, W, k=1))\n",
    "    D_vertical = sparse.kron(sparse.eye(H-1, H, k=0) - sparse.eye(H-1, H, k=1), sparse.eye(W))\n",
    "    D = sparse.vstack((D_horizontal, D_vertical))\n",
    "    D = D.tocsr()\n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def test_difference_matrix(image_shape):\n",
    "    D = difference_matrix(image_shape)\n",
    "    #print(D.toarray().astype(\"int\"))\n",
    "    H, W = image_shape\n",
    "    assert D.shape == (2 * H * W - H - W, H * W), \"difference matrix has wrong dimension\"\n",
    "test_difference_matrix((3,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Generate test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def distortion(distortion_matrix, img):\n",
    "    \"\"\"simple matrix vector product\"\"\"\n",
    "    return distortion_matrix.dot(img.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Solve regularized Least Squares Problem: `x = reg_lstsq(A, b, D, reg_param=0.1)`**\n",
    "\n",
    "$$\n",
    "(A^\\top A + \\delta D^\\top D) x = A^\\top b. \n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def reg_lstsq(A, b, D, reg_param=0.1, verbose=1):\n",
    "    \"\"\"A csr nxn, b vector nx1, D csr pxn, delta float\"\"\"\n",
    "    import scipy.sparse.linalg\n",
    "    _delta = reg_param\n",
    "    n = len(b)\n",
    "    if verbose:\n",
    "        print(\"start solving\")\n",
    "    recon_img = scipy.sparse.linalg.gmres(A.T @ A + _delta * D.T @ D, A.T.dot(b), maxiter=1)[0]\n",
    "    if verbose:\n",
    "        print(\"finished solving\")\n",
    "    # scipy.sparse.linalg.spsolve(A.T@A + _delta * D.T@D, A.dot(b))#\n",
    "    return recon_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Experimenting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def experiment(path_to_image, percentage, reg_param, save=False):\n",
    "       \n",
    "    from PIL import Image\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt   \n",
    "    from IPython.display import set_matplotlib_formats\n",
    "    set_matplotlib_formats('svg')  \n",
    "    %matplotlib qt\n",
    "    \n",
    "    original_img = np.array(Image.open(path_to_image).convert(\"L\"))\n",
    "    img_shape = np.shape(original_img)\n",
    "    print(\"Resolution:\", img_shape)\n",
    "    \n",
    "    dim = np.prod(img_shape)\n",
    "    A = masking_matrix(img_shape, percentage)   \n",
    "    b = distortion(A, original_img).ravel()\n",
    "    D = difference_matrix(img_shape) \n",
    "    recon_img = reg_lstsq(A, b, D, reg_param=reg_param)\n",
    "   \n",
    "    plt.figure(\"Image Inpainting\")\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(original_img, cmap='gray')\n",
    "    plt.title(\"original\")\n",
    "    plt.axis(False)\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(b.reshape(img_shape), cmap='gray')\n",
    "    plt.title(\"masked image: {}% of pixels randomly lost\".format((1-percentage)*100))\n",
    "    plt.axis(False)\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(recon_img.reshape(img_shape), cmap='gray')\n",
    "    plt.axis(False)\n",
    "    plt.title(\"reconstructed image: reg-param delta={}\".format(reg_param))\n",
    "    plt.show()\n",
    "    \n",
    "    if save:\n",
    "        plt.savefig(\"Image_Inpainting\", dpi='figure')\n",
    "        \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "path_to_image = \"kalle.jpg\"\n",
    "percentage = 0.1  #0.01  # we randomly keep 100*percentage % of the data\n",
    "reg_param = 0.01  # regularization parameter\n",
    "save = False\n",
    "# \n",
    "%matplotlib inline\n",
    "experiment(path_to_image, percentage, reg_param, save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Play\n",
    "\n",
    "- Play around with different choices for the parameters `reg_param` and `percentage` as well as `maxiter` for GMRES\n",
    "- Would your machine cope with dense arrays?\n",
    "- Patch: Instead of removing randomized set of pixels, remove a patch of the image. Can you reconstruct it?\n",
    "- Unknown data: Can you define the operator $A$ from given data?"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
